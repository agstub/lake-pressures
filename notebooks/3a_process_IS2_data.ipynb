{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Pre-process ICESat-2 elevation-change data (ATL15 gridded product)\n",
    "## This script preprocesses the ICESat-2 data for use in the inversion\n",
    "\n",
    "**OVERVIEW**\n",
    "\n",
    "The main choices are specifying:\n",
    "\n",
    "(I) lake_name (str): name of lake from the inventory:\n",
    "\n",
    "   Siegfried, M. R., & Fricker, H. A. (2018). Thirteen years of subglacial lake\n",
    "   activity in Antarctica from multi-mission satellite altimetry. Annals of\n",
    "   Glaciology, 59(76pt1), 42-55.\n",
    "\n",
    "(II) L0 (float):  half-length(/half-width) of horizontal domain (a box) surrounding\n",
    "                   the subglacial lake that was selected in the first step\n",
    "\n",
    " *There is also a function below (\"localize\") that removes the off-lake component\n",
    "  of the elevation change at each timestep (regional thickening or thinning signal)\n",
    "\n",
    "**DATA REQUIREMENTS:** see README\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '../source')\n",
    "sys.path.insert(0, '../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available subglacial lake names from Siegfried & Fricker (2018) inventory\n",
    "from load_lakes import gdf\n",
    "print(gdf['name'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lake name to one of the names above\n",
    "import metavars\n",
    "metavars.lake_name = 'MercerSubglacialLake'        # set to 'synth' or one of the lakes in the inventory\n",
    "lake_name = metavars.lake_name\n",
    "data_name = 'data_'+lake_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to ICESat-2 ATL15 data\n",
    "paths = {}\n",
    "if lake_name == 'MercerSubglacialLake' or lake_name == 'Mac1':\n",
    "    paths['icesat'] = '/Users/agstubbl/Desktop/ICESat-2/ATL15_A3_0321_01km_004_01.nc'\n",
    "elif lake_name == 'Byrd_s10' or lake_name == 'Cook_E2':\n",
    "    paths['icesat'] = '/Users/agstubbl/Desktop/ICESat-2/ATL15_A3_0321_01km_004_01.nc'    \n",
    "else:\n",
    "    print('set icesat-2 file appropriately for given lake')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we subset the data and interpolate onto a finer spatiotemporal grid.\n",
    "\n",
    "**Note:** this can take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../source')\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from load_lakes import gdf\n",
    "\n",
    "outline = gdf.loc[gdf['name']==lake_name]\n",
    "if os.path.isdir('../data/'+data_name)==False:\n",
    "    os.mkdir('../data/'+data_name)\n",
    "x0 = float(outline.centroid.x.iloc[0])*1e3\n",
    "y0 = float(outline.centroid.y.iloc[0])*1e3\n",
    "\n",
    "# STEP (II): Select half-width L0 of box surrounding lake\n",
    "L0 = 30*1000\n",
    "x_min = x0-L0\n",
    "x_max = x0+L0\n",
    "y_min = y0-L0\n",
    "y_max = y0+L0\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "# load the ATL15 data\n",
    "fn = paths['icesat']\n",
    "ds = nc.Dataset(fn)\n",
    "dsh = ds['delta_h']\n",
    "\n",
    "dh = dsh['delta_h'][:]        # elevation change (m)\n",
    "x = dsh['x'][:]               # x coordinate array (m)\n",
    "y = dsh['y'][:]               # y coordinate array (m)\n",
    "t = dsh['time'][:]            # t coordinate array (d)\n",
    "\n",
    "nt = np.size(t)\n",
    "\n",
    "ind_x = np.arange(0,np.size(x),1)\n",
    "ind_y = np.arange(0,np.size(y),1)\n",
    "\n",
    "# extract the data that is inside the bounding box\n",
    "x_sub = x[(x>=x_min)&(x<=x_max)]\n",
    "y_sub = y[(y>=y_min)&(y<=y_max)]\n",
    "inds_x = ind_x[(x>=x_min)&(x<=x_max)]\n",
    "inds_y = ind_y[(y>=y_min)&(y<=y_max)]\n",
    "\n",
    "nx = np.size(inds_x)\n",
    "ny = np.size(inds_y)\n",
    "\n",
    "inds_xy = np.ix_(inds_y,inds_x)\n",
    "dh_sub = np.zeros((nt,ny,nx))\n",
    "\n",
    "# put elevation change maps into 3D array with time being the first index\n",
    "for i in range(nt):\n",
    "    dh0 = dh[i,:,:]\n",
    "    dh_sub[i,:,:] = dh0[inds_xy]\n",
    "\n",
    "#--------------------------PLOTTING-------------------------------\n",
    "\n",
    "levels=np.arange(-1,1.1,0.1)*np.max(np.abs(dh_sub))\n",
    "\n",
    "# plot png at each time step\n",
    "\n",
    "if os.path.isdir('../data/'+data_name+'/data_pngs')==False:\n",
    "    os.mkdir('../data/'+data_name+'/data_pngs')\n",
    "\n",
    "X_sub,Y_sub = np.meshgrid(x_sub,y_sub)\n",
    "\n",
    "\n",
    "# PLOT elevation change anomaly\n",
    "for i in range(np.size(t)):\n",
    "    \n",
    "    plt.close()\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.title(r'$t=$ '+'{:.2f}'.format(t[i])+' d',fontsize=24)\n",
    "    p = plt.contourf(X_sub/1e3,Y_sub/1e3,dh_sub[i,:,:],levels=levels,cmap='coolwarm',extend='both')\n",
    "    outline.plot(edgecolor='k',facecolor='none',ax=plt.gca(),linewidth=3)\n",
    "    plt.xlabel(r'$x$ (km)',fontsize=20)\n",
    "    plt.ylabel(r'$y$ (km)',fontsize=20)\n",
    "    cbar = plt.colorbar(p)\n",
    "    cbar.set_label(r'$dh$ (m)',fontsize=20)\n",
    "    cbar.ax.tick_params(labelsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/'+data_name+'/data_pngs/dh_'+str(i))\n",
    "    plt.close()\n",
    "print('saved some images of elevation change maps in the data directory!')\n",
    "\n",
    "##------------------------------------------------------------------------------\n",
    "## INTERPOLATE DATA\n",
    "\n",
    "def interp_tyx(f,t,y,x):\n",
    "    Nx_f = 101            # fine Nx\n",
    "    Ny_f = 101            # fine Ny\n",
    "    Nt_f = 100            # fine Nt\n",
    "\n",
    "    t0_f = np.linspace(t.min(),t.max(),num=Nt_f)  # fine time array\n",
    "    x0_f = np.linspace(x.min(),x.max(),num=Nx_f)  # fine x coordinate array\n",
    "    y0_f = np.linspace(y.min(),y.max(),num=Ny_f)  # fine y coordinate array\n",
    "    t_f,y_f,x_f = np.meshgrid(t0_f,y0_f,x0_f,indexing='ij')\n",
    "\n",
    "    points = (t_f,y_f,x_f)\n",
    "\n",
    "    f_fine = griddata((t.ravel(),y.ravel(),x.ravel()),f.ravel(),points)\n",
    "\n",
    "    return f_fine,t0_f,y0_f,x0_f\n",
    "\n",
    "\n",
    "\n",
    "t_g,y_g,x_g = np.meshgrid(t,y_sub,x_sub,indexing='ij')\n",
    "\n",
    "dh_f,t_f,y_f,x_f = interp_tyx(dh_sub,t_g,y_g,x_g)\n",
    "\n",
    "t,y,x = np.meshgrid(t_f,y_f,x_f,indexing='ij')\n",
    "\n",
    "def localize(f):\n",
    "    f_far = np.copy(f)\n",
    "    f_far[np.sqrt((x-x.mean())**2+(y-y.mean())**2)<0.8*np.sqrt((x-x.mean())**2+(y-y.mean())**2).max()] = 0\n",
    "    F = (f_far != 0).sum(axis=(1,2))+1e-10\n",
    "    f_far = f_far.sum(axis=(1,2))/F\n",
    "    f_loc = f- np.multiply.outer(f_far,np.ones(np.shape(f[0,:,:])))\n",
    "    return f_loc\n",
    "\n",
    "dh_loc = localize(dh_f)\n",
    "\n",
    "off_lake = dh_f-dh_loc\n",
    "off_lake = off_lake[:,0,0]\n",
    "\n",
    "\n",
    "# ----------------------------- SAVE DATA --------------------------------------\n",
    "np.save('../data/'+data_name+'/h_obs.npy',dh_loc)          # elevation anomaly: (m)\n",
    "np.save('../data/'+data_name+'/off_lake.npy',off_lake)     # off-lake timeseries: (m)\n",
    "np.save('../data/'+data_name+'/t.npy',(t_f-t_f[0])/365.0)  # time: (yr)\n",
    "np.save('../data/'+data_name+'/x_d.npy',x_f/1e3)           # x coord. (km)\n",
    "np.save('../data/'+data_name+'/y_d.npy',y_f/1e3)           # y coord. (km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save some placeholder arrays that will be filled in the next notebook from ISSM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/'+data_name+'/eta.npy',np.array([1]))    # viscosity: Pa s\n",
    "np.save('../data/'+data_name+'/beta.npy',np.array([1]))   # basal drag: Pa s / m\n",
    "np.save('../data/'+data_name+'/H.npy',np.array([1]))      # thickness: m\n",
    "np.save('../data/'+data_name+'/u.npy',np.array([0]))      # vel x: m/yr\n",
    "np.save('../data/'+data_name+'/v.npy',np.array([0]))      # vel y: m/yr\n",
    "np.save('../data/'+data_name+'/x.npy',np.array([0,1]))    # x coord (scaled)\n",
    "np.save('../data/'+data_name+'/y.npy',np.array([0,1]))    # y coord (scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
